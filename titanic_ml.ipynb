{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e34d97eb",
   "metadata": {},
   "source": [
    "## Kaggle Titanic Entry\n",
    "### Daniel Walker, PhD\n",
    "### 12 APRIL 2021\n",
    "\n",
    "Purpose: Predict whether passengers Survived (1) or did not (0). \n",
    "Output: CSV file with 418 entries - one entry per passenger in test set, with 2 columns: `PassengerId` and `Survived`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0e864",
   "metadata": {},
   "source": [
    "### Import Data & Take a Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea092cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "test_data_path = os.path.join(cwd, 'titanic_data', 'test.csv')\n",
    "train_data_path = os.path.join(cwd, 'titanic_data', 'train.csv')\n",
    "test = pd.read_csv(test_data_path)\n",
    "train = pd.read_csv(train_data_path)\n",
    "gender = pd.read_csv(os.path.join(cwd, 'titanic_data', 'gender_submission.csv'))\n",
    "gender.head()\n",
    "#Gender = example answer submission if only all female passengers survived.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a68b33f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin evaluating the data\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bd855b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e026fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Why does train have one more column?\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9975d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2635d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer, test does not have a target variable - 'Survived' in train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e3a86f",
   "metadata": {},
   "source": [
    "The preceding two tables highlight a couple of things about the data:\n",
    "- Test does not include the target variable\n",
    "- Cabin & Age are going to be the two most problematic variables, both of which have a large number of NaNs in both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "425beedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45     NaN\n",
       "96     C46\n",
       "349    NaN\n",
       "70     NaN\n",
       "319    NaN\n",
       "30     NaN\n",
       "274    NaN\n",
       "241    NaN\n",
       "52     NaN\n",
       "67     NaN\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Cabin'].sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26452391",
   "metadata": {},
   "source": [
    "The sample above shows that the `Cabin` variable is an alphanumeric code. If required, I could split the leading letter & the following numbers into two variables that may be informative, but will for now progress without `Cabin` in my analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d907942",
   "metadata": {},
   "source": [
    "### Analytical Plan\n",
    "\n",
    "1. Train separate algorithms to predict missing Age and Cabin entries.\n",
    "- I suspect Age will have better results than Cabin\n",
    "- In the test data, 331 observations have `Age` + `Fare`. Only one record is missing `Fare`. I will split these into training & validation sets, then make predictions on the remaining (418-331) passengers plus any passengers missing in\n",
    "2. With data sets more evenly populated, evaluate model accuracy with & without imputed variables\n",
    "- If my suspicion is correct, will probably wind up dropping cabin/using another variable for being too correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19af4fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error is 5.7459859615735365 and test error is 7.0\n"
     ]
    }
   ],
   "source": [
    "# Train model to impute Age for Test data set\n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# OHE catgorical vars, Scale continuous vars\n",
    "# Split out useful vars\n",
    "age_all = train[[\"Age\",\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]].dropna()\n",
    "age_y = age_all[\"Age\"]\n",
    "age_x = age_all[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "age_x_cont = age_x[[\"Pclass\", \"SibSp\", \"Fare\"]]\n",
    "age_x_cat = age_x[[\"Sex\", \"Embarked\"]]\n",
    "# OHE cat vars\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(age_x_cat)\n",
    "age_x_cat_t = enc.transform(age_x_cat).toarray()\n",
    "# Scale cont vars\n",
    "scaler = StandardScaler().fit(age_x_cont)\n",
    "age_x_cont_s = scaler.transform(age_x_cont)\n",
    "# Rejoin two numpy arrays\n",
    "age_x_format = np.concatenate((age_x_cat_t, age_x_cont_s), axis=1)\n",
    "# Shape checks out\n",
    "# Split into training & test sets\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(age_x_format, \n",
    "                                                                    age_y, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    random_state=865)\n",
    "\n",
    "# Init model with default params using MAE loss function\n",
    "gb_reg = ensemble.GradientBoostingRegressor(n_estimators=1000,\n",
    "                                             loss='lad',\n",
    "                                             learning_rate=0.01,\n",
    "                                             max_depth=4,\n",
    "                                             random_state=865).fit(X_train_age, y_train_age)\n",
    "tr_mae = median_absolute_error(y_train_age, gb_reg.predict(X_train_age))\n",
    "ts_mae = median_absolute_error(y_test_age, gb_reg.predict(X_test_age))\n",
    "\n",
    "print(f'Training error is {tr_mae} and test error is {ts_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b2f5a",
   "metadata": {},
   "source": [
    "Documenting my age predictor training & test errors here:\n",
    "First run: tr = 8.6, ts = 9.8\n",
    "Second run (learning_rate from 0.1 -> 0.01) = worse\n",
    "Third: (learning=0.1, max_depth from 1 -> 6) = marginally better\n",
    "...repeat several times...\n",
    "Changed from mean absolute error to median absolute error and the values fell. That means age is impacted by outliers.\n",
    "Current errors:\n",
    "tr = 5.91 years over, ts = 6.955.\n",
    "Rounding those numbers to nearest year (7 in test data).\n",
    "I should be able to get away with subtracting 7 years from all imputed ages in my final data to improve my predictions.\n",
    "Lots of additional manual attempts show that this model has a keen test error floo\n",
    "\n",
    "\n",
    "Hilariously, properly handling the categorical & continuous variables decreased my model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c6b88b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 7)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use gb_reg - 7 to impute missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce243585",
   "metadata": {},
   "source": [
    "In this next section,  I will see if a simple neural net does a better job of imputing missing `Age` values than I have been able to do with the GBRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55184179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567c59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
